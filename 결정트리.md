# 목표

## ML을 위한 패키지 삽입


```python
import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
```

## 데이터 프레임 데이터 상태 한눈에 보기


```python
wine = pd.read_csv("https://bit.ly/wine_csv_data")
```


```python
#상위 5개의 샘픙을 확인 할수 있는 메서드 head()
wine.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>alcohol</th>
      <th>sugar</th>
      <th>pH</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>9.4</td>
      <td>1.9</td>
      <td>3.51</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9.8</td>
      <td>2.6</td>
      <td>3.20</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>9.8</td>
      <td>2.3</td>
      <td>3.26</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9.8</td>
      <td>1.9</td>
      <td>3.16</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9.4</td>
      <td>1.9</td>
      <td>3.51</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
#데이터 프레임에서 각열의 데이터 타입과 누락된 데이터 확인할 수 있는 메서드 info()
wine.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 6497 entries, 0 to 6496
    Data columns (total 4 columns):
     #   Column   Non-Null Count  Dtype  
    ---  ------   --------------  -----  
     0   alcohol  6497 non-null   float64
     1   sugar    6497 non-null   float64
     2   pH       6497 non-null   float64
     3   class    6497 non-null   float64
    dtypes: float64(4)
    memory usage: 203.2 KB



```python
#데이터 프레임 열에대한 간략한 통계를 확인할 수 있는 메서드 describe()
wine.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>alcohol</th>
      <th>sugar</th>
      <th>pH</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>6497.000000</td>
      <td>6497.000000</td>
      <td>6497.000000</td>
      <td>6497.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>10.491801</td>
      <td>5.443235</td>
      <td>3.218501</td>
      <td>0.753886</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.192712</td>
      <td>4.757804</td>
      <td>0.160787</td>
      <td>0.430779</td>
    </tr>
    <tr>
      <th>min</th>
      <td>8.000000</td>
      <td>0.600000</td>
      <td>2.720000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>9.500000</td>
      <td>1.800000</td>
      <td>3.110000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>10.300000</td>
      <td>3.000000</td>
      <td>3.210000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>11.300000</td>
      <td>8.100000</td>
      <td>3.320000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>14.900000</td>
      <td>65.800000</td>
      <td>4.010000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>



## 데이터 가공하기


```python
data = wine[['alcohol','sugar','pH']].to_numpy()
target = wine[['class']].to_numpy()
```


```python
train_data,test_data,train_target,test_target = train_test_split(data,target,test_size = 0.2,random_state = 42)
```


```python
ss = StandardScaler()
ss.fit(train_data)
train_scaled = ss.transform(train_data)
test_scaled = ss.transform(test_data)
```

## ML


```python
from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(train_scaled,train_target)
print(lr.score(train_scaled,train_target))
print(lr.score(test_scaled,test_target))
```

    0.7808350971714451
    0.7776923076923077


    C:\Anaconda3\lib\site-packages\sklearn\utils\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
      y = column_or_1d(y, warn=True)


점수가 높지 않다!

화이트 와인을 골라내는 것이 생각보다 수월하지 않고 있다. 이를 해결하기 위해 매개변수 C값을 조정 해주어도 된다.

하지만 다른 알고리즘을 선택해서 해결해보겠다

## 결정트리

* 설명하기 쉬운 모델 결정트리!

### 결정 트리 모델


```python
from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier()
dt.fit(train_scaled,train_target)

print(dt.score(train_scaled, train_target))
print(dt.score(test_scaled,test_target))
```

    0.996921300750433
    0.8553846153846154


훈련 모델에 대한 정확도가 매우높고 테스트 모델에 대한 정확도는 다소 낮다.

과대적합 상태이다.

### 결정트리 시각화


```python
from sklearn.tree import plot_tree

plt.figure(figsize = (10,7))
plot_tree(dt)
plt.show()
```


![output_20_0](https://user-images.githubusercontent.com/97498405/160272695-fde8e497-3299-45c7-b762-72a28c7122b9.png)
    



```python
plt.figure(figsize = (10,7))
plot_tree(dt, max_depth = 1,filled=True,feature_names=['alcohol','sugar','pH'])
plt.show()
```


![output_21_0](https://user-images.githubusercontent.com/97498405/160272711-3d346cfa-de65-4c2a-a213-5f9cd0b47892.png)
    


### 결정트리의 과대적합 방지 - 가지치기


```python
dt = DecisionTreeClassifier(max_depth = 3, random_state = 42)
dt.fit(train_scaled,train_target)

print(dt.score(train_scaled,train_target))
print(dt.score(test_scaled,test_target))
```

    0.8454877814123533
    0.8415384615384616



```python
plt.figure(figsize = (20,15))
plot_tree(dt,filled = True, feature_names = ['alcohol','sugar','pH'])
plt.show()
```


​    
![output_24_0](https://user-images.githubusercontent.com/97498405/160272726-4fa04bd8-8536-419e-9fe3-579866517d6d.png)
​    


깊이가 3인 결정트리로 학습을 하니 과소적합!

그리고 결정트리 알고리즘은 데이터 전처리(정규화) 과정이 필요없다!


```python
dt = DecisionTreeClassifier(max_depth = 3, random_state = 42)
dt.fit(train_data,train_target)

print(dt.score(train_data,train_target))
print(dt.score(test_data,test_target))
```

    0.8454877814123533
    0.8415384615384616


결과가 차이가없음을 확인 할 수 있다!

결정 트리에서 어떤 특성이 가장 유용한지 나타내는 특성중요도 또한 출력이 가능하다!


```python
print('alcohol','sugar','pH')
print(dt.feature_importances_)
```

    alcohol sugar pH
    [0.12345626 0.86862934 0.0079144 ]

